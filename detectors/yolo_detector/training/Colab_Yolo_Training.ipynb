{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yolo object detector ",
      "provenance": [],
      "collapsed_sections": [
        "HCXEbU_Bywsi",
        "AvukO0eJzukm",
        "noLLWRODBzmV",
        "yX8vn6Xm7tN9",
        "pgNSbzWa_USU",
        "mNtGDlMz_eoj",
        "mv-FSrMc90qc",
        "E-KYcFMVEIAE"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCXEbU_Bywsi"
      },
      "source": [
        "# Introduction\n",
        "This notebook shows how to setup the darknet framework, required for training the yolo object detector.\n",
        "For the purpose the provided GPU environment by Google Colab will be used.\n",
        "The project is using google drive to save the project files generated by the executed steps in this notebook. Of course, this is not required but is done out of convinience, so it is not required to build the project every time it is used.**bold text**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdSHlK359MMy"
      },
      "source": [
        "1. Import colab and drive API\n",
        "2. Set workingspace directory to our google drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvukO0eJzukm"
      },
      "source": [
        "# Setting up Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf8zIQ4d7TEA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "058274c2-34ff-4e79-e8bc-e419ac216b3e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALr2VKn39VPc"
      },
      "source": [
        "1. Next navigate to our desired folder \n",
        "Using cd /content/gdrive/My Drive/... Folder you want.\n",
        "You can make new directory by using mkdir ... - name of the folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IAfDF6a-539"
      },
      "source": [
        "List the contents of our directory to make sure its what we expect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXKGjG8F8J2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a99997-7626-4e60-a9f4-87d118e3a9d1"
      },
      "source": [
        "!ls\n",
        "%cd /content/drive/My Drive/sewer_inspection/yolo_detector\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cv2.cpython-36m-x86_64-linux-gnu.so  drive  infered1.avi  sample_data\n",
            "/content/drive/My Drive/sewer_inspection/yolo_detector\n",
            "config_weights\tcv  darknet  infered.avi  Notebooks  yolo_base\tyolo_detector\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmDvBgSQ00NA"
      },
      "source": [
        "## Creating a symbolic link (optional)\n",
        "This step is optional, but it is recommend since it really makes working with paths in the google colab environment a lot more comfortable, especially if there are any spaces somewhere in you path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62jwDQC30ziM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3f2d409-584b-478b-e0b4-89ba02179791"
      },
      "source": [
        "# create symbolic link for easier access to my drive\n",
        "!ln -s \"/content/drive/My Drive/sewer_inspection/yolo_detector/\" yolo_base"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ln: failed to access 'yolo_base': Operation not supported\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTpKFWHg3JY_"
      },
      "source": [
        "Now every time we have to give the path to the directory where darknet for example will be installed we can use yolo_base instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66ec3Wqw__yK"
      },
      "source": [
        "The following following steps are to train YoloV4 model on our custom dataset.\n",
        "The dataset is label with roboflow - that allows up to 500 images for free in our dataset. <br>\n",
        "What we are going to try here is to use google drive as our filesystem and save and training progress to our drive, so we do not loose weights after reaching the limit for the GPU access which is 12h. <br>\n",
        "[This](https://colab.research.google.com/drive/1mzL6WyY9BRx4xX476eQdhKDnd_eixBlG#scrollTo=GNVU7eu9CQj3) is the tutorial that was followed in order to realise this project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riuDQw5XAtya"
      },
      "source": [
        "# Configuring environment for Darknet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgS1uAp-A1YQ"
      },
      "source": [
        "# CUDA: Let's check that Nvidia CUDA drivers are already pre-installed and which version is it.\n",
        "!/usr/local/cuda/bin/nvcc --version\n",
        "# We need to install the correct cuDNN according to this output\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mL5As4k3jx5"
      },
      "source": [
        "## Set compute capability\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODpDNGDC30ML"
      },
      "source": [
        "Change the number depending on what GPU is listed above, under NVIDIA-SMI > Name.\n",
        "* Tesla K80: 30\n",
        "* Tesla P100: 60\n",
        "* Tesla T4: 75"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d3LYkeRCafM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bec8701-b1f7-4939-f796-5c5a647e691a"
      },
      "source": [
        "%env compute_capability=61"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: compute_capability=61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noLLWRODBzmV"
      },
      "source": [
        "# Installing darknet on Colab\n",
        "The following steps show how to install darknet in the working environment.\n",
        "If you chose to mount google drive, the progress from the following cells can be saved and you wont have to repeat those steps again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHcLqeAf4eSI"
      },
      "source": [
        "The cell below will remove darknet directory if there is one and clone the Darknet repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClJKf6S047pu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36377914-01b9-4e19-f974-e4012f9d1613"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3rdparty\tdarknet\t\t\tinclude\t\t       README.md\n",
            "backup\t\tDarknetConfig.cmake.in\tjson_mjpeg_streams.sh  results\n",
            "build\t\tdarknet_images.py\tLICENSE\t\t       scripts\n",
            "build.ps1\tdarknet.py\t\tMakefile\t       src\n",
            "build.sh\tdarknet_video.py\tnet_cam_v3.sh\t       video_yolov3.sh\n",
            "cfg\t\tdata\t\t\tnet_cam_v4.sh\t       video_yolov4.sh\n",
            "cmake\t\timage_yolov3.sh\t\tobj\t\t       yolov4.weights\n",
            "CMakeLists.txt\timage_yolov4.sh\t\tpredictions.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ7RrkGGBzKX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bce70ea-55a3-461d-b645-ecf05ebfff98"
      },
      "source": [
        "%rm -rf darknet\n",
        "#we clone the fork of darknet maintained by roboflow\n",
        "#small changes have been made to configure darknet for training\n",
        "!git clone https://github.com/AlexeyAB/darknet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'darknet'...\n",
            "remote: Enumerating objects: 14370, done.\u001b[K\n",
            "remote: Total 14370 (delta 0), reused 0 (delta 0), pack-reused 14370\u001b[K\n",
            "Receiving objects: 100% (14370/14370), 13.09 MiB | 22.88 MiB/s, done.\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_zi9L5JB_dN"
      },
      "source": [
        "#install environment from the Makefile\n",
        "#note if you are on Colab Pro this works on a P100 GPU\n",
        "#if you are on Colab free, you may need to change the Makefile for the K80 GPU\n",
        "#this goes for any GPU, you need to change the Makefile to inform darknet which GPU you are running on.\n",
        "%cd darknet/\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/g' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/g' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/g' Makefile\n",
        "!sed -i \"s/ARCH= -gencode arch=compute_60,code=sm_60/ARCH= -gencode arch=compute_${compute_capability},code=sm_${compute_capability}/g\" Makefile\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX8vn6Xm7tN9"
      },
      "source": [
        "#Test pre-trained yolo detector\n",
        "\n",
        "In the next cell the weights for yolo4 trained on coco dataset are downloaded and tested"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXfa-soG-nAg"
      },
      "source": [
        "The next cell downloads the config and weights for yolo trained on coco dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cOFJSzU7-8M"
      },
      "source": [
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx2sq2B5-vyI"
      },
      "source": [
        "The following cells contains some functionts that will help us show the results from running the detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgNSbzWa_USU"
      },
      "source": [
        "## Testing yolo 4 trained on coco dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omo87Y6q-MW9"
      },
      "source": [
        "# define helper functions\n",
        "def imShow(path):\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()\n",
        "\n",
        "# use this to upload files\n",
        "def upload():\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload() \n",
        "  for name, data in uploaded.items():\n",
        "    with open(name, 'wb') as f:\n",
        "      f.write(data)\n",
        "      print ('saved file', name)\n",
        "\n",
        "# use this to download a file  \n",
        "def download(path):\n",
        "  from google.colab import files\n",
        "  files.download(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pU-F8i--4pG"
      },
      "source": [
        "The cell below, once executed will run darknet with the yolo4 detector trained on the coco dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZxKDb2gPCKT"
      },
      "source": [
        "!./darknet detect cfg/yolov4.cfg yolov4.weights data/dog.jpg\n",
        "imShow('predictions.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNtGDlMz_eoj"
      },
      "source": [
        "# Training custom yolo 4 detector\n",
        "The following cells when after executed will create custom yolo 4 configuration that can be trained on our own dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv-FSrMc90qc"
      },
      "source": [
        "## Download dataset\n",
        "Using roboflow to create dataset. Download using the link provided by roboflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM-vg4rkC8uu"
      },
      "source": [
        "#if you already have YOLO darknet format, you can skip this step\n",
        "%cd yolo_base/darknet\n",
        "#!curl -L https://app.roboflow.com/ds/NH2ig2l5j5?key=S4Qkqs3roo > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EMgxhDWDHZS"
      },
      "source": [
        "#Set up training file directories for custom dataset\n",
        "%cd yolo_base/darknet #%cd /content/gdrive/My Drive/NNTraining/darknet\n",
        "%cp train/_darknet.labels data/obj.names\n",
        "%mkdir data/obj\n",
        "#copy image and labels\n",
        "%cp train/*.jpg data/obj/\n",
        "%cp valid/*.jpg data/obj/\n",
        "\n",
        "%cp train/*.txt data/obj/\n",
        "%cp valid/*.txt data/obj/\n",
        "\n",
        "with open('data/obj.data', 'w') as out:\n",
        "  out.write('classes = 3\\n')\n",
        "  out.write('train = data/train.txt\\n')\n",
        "  out.write('valid = data/valid.txt\\n')\n",
        "  out.write('names = data/obj.names\\n')\n",
        "  out.write('backup = backup/')\n",
        "\n",
        "#write train file (just the image list)\n",
        "import os\n",
        "\n",
        "with open('data/train.txt', 'w') as out:\n",
        "  for img in [f for f in os.listdir('train') if f.endswith('jpg')]:\n",
        "    out.write('data/obj/' + img + '\\n')\n",
        "\n",
        "#write the valid file (just the image list)\n",
        "import os\n",
        "\n",
        "with open('data/valid.txt', 'w') as out:\n",
        "  for img in [f for f in os.listdir('valid') if f.endswith('jpg')]:\n",
        "    out.write('data/obj/' + img + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lqFaMKPDWPJ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFFp5_YlDadv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "45608d0c-0c89-434f-ada3-076f7954cbd4"
      },
      "source": [
        "#we build config dynamically based on number of classes\n",
        "#we build iteratively from base config files. This is the same file shape as cfg/yolo-obj.cfg\n",
        "def file_len(fname):\n",
        "  with open(fname) as f:\n",
        "    for i, l in enumerate(f):\n",
        "      pass\n",
        "  return i + 1\n",
        "\n",
        "num_classes = file_len('train/_darknet.labels')\n",
        "print(\"writing config for a custom YOLOv4 detector detecting number of classes: \" + str(num_classes))\n",
        "\n",
        "#Instructions from the darknet repo\n",
        "#change line max_batches to (classes*2000 but not less than number of training images, and not less than 6000), f.e. max_batches=6000 if you train for 3 classes\n",
        "#change line steps to 80% and 90% of max_batches, f.e. steps=4800,5400\n",
        "if os.path.exists('./cfg/custom-yolov4-detector.cfg'): os.remove('./cfg/custom-yolov4-detector.cfg')\n",
        "\n",
        "\n",
        "with open('./cfg/custom-yolov4-detector.cfg', 'a') as f:\n",
        "  f.write('[net]' + '\\n')\n",
        "  f.write('batch=64' + '\\n')\n",
        "  #####smaller subdivisions help the GPU run faster. 12 is optimal, but you might need to change to 24,36,64####\n",
        "  f.write('subdivisions=24' + '\\n')\n",
        "  f.write('width=416' + '\\n')\n",
        "  f.write('height=416' + '\\n')\n",
        "  f.write('channels=3' + '\\n')\n",
        "  f.write('momentum=0.949' + '\\n')\n",
        "  f.write('decay=0.0005' + '\\n')\n",
        "  f.write('angle=0' + '\\n')\n",
        "  f.write('saturation = 1.5' + '\\n')\n",
        "  f.write('exposure = 1.5' + '\\n')\n",
        "  f.write('hue = .1' + '\\n')\n",
        "  f.write('\\n')\n",
        "  f.write('learning_rate=0.001' + '\\n')\n",
        "  f.write('burn_in=1000' + '\\n')\n",
        "  ######you can adjust up and down to change training time#####\n",
        "  ##Darknet does iterations with batches, not epochs####\n",
        "  max_batches = num_classes*2000\n",
        "  #max_batches = 2000\n",
        "  f.write('max_batches=' + str(max_batches) + '\\n')\n",
        "  f.write('policy=steps' + '\\n')\n",
        "  steps1 = .8 * max_batches\n",
        "  steps2 = .9 * max_batches\n",
        "  f.write('steps='+str(steps1)+','+str(steps2) + '\\n')\n",
        "\n",
        "#Instructions from the darknet repo\n",
        "#change line classes=80 to your number of objects in each of 3 [yolo]-layers:\n",
        "#change [filters=255] to filters=(classes + 5)x3 in the 3 [convolutional] before each [yolo] layer, keep in mind that it only has to be the last [convolutional] before each of the [yolo] layers.\n",
        "\n",
        "  with open('cfg/yolov4-custom2.cfg', 'r') as f2:\n",
        "    content = f2.readlines()\n",
        "    for line in content:\n",
        "      f.write(line)    \n",
        "    num_filters = (num_classes + 5) * 3\n",
        "    f.write('filters='+str(num_filters) + '\\n')\n",
        "    f.write('activation=linear')\n",
        "    f.write('\\n')\n",
        "    f.write('\\n')\n",
        "    f.write('[yolo]' + '\\n')\n",
        "    f.write('mask = 0,1,2' + '\\n')\n",
        "    f.write('anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401' + '\\n')\n",
        "    f.write('classes=' + str(num_classes) + '\\n')\n",
        "\n",
        "  with open('cfg/yolov4-custom3.cfg', 'r') as f3:\n",
        "    content = f3.readlines()\n",
        "    for line in content:\n",
        "      f.write(line)    \n",
        "    num_filters = (num_classes + 5) * 3\n",
        "    f.write('filters='+str(num_filters) + '\\n')\n",
        "    f.write('activation=linear')\n",
        "    f.write('\\n')\n",
        "    f.write('\\n')\n",
        "    f.write('[yolo]' + '\\n')\n",
        "    f.write('mask = 3,4,5' + '\\n')\n",
        "    f.write('anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401' + '\\n')\n",
        "    f.write('classes=' + str(num_classes) + '\\n')\n",
        "\n",
        "  with open('cfg/yolov4-custom4.cfg', 'r') as f4:\n",
        "    content = f4.readlines()\n",
        "    for line in content:\n",
        "      f.write(line)    \n",
        "    num_filters = (num_classes + 5) * 3\n",
        "    f.write('filters='+str(num_filters) + '\\n')\n",
        "    f.write('activation=linear')\n",
        "    f.write('\\n')\n",
        "    f.write('\\n')\n",
        "    f.write('[yolo]' + '\\n')\n",
        "    f.write('mask = 6,7,8' + '\\n')\n",
        "    f.write('anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401' + '\\n')\n",
        "    f.write('classes=' + str(num_classes) + '\\n')\n",
        "    \n",
        "  with open('cfg/yolov4-custom5.cfg', 'r') as f5:\n",
        "    content = f5.readlines()\n",
        "    for line in content:\n",
        "      f.write(line)\n",
        "\n",
        "print(\"file is written!\")    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "writing config for a custom YOLOv4 detector detecting number of classes: 5\n",
            "file is written!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EFC4x82DfAF"
      },
      "source": [
        "#here is the file that was just written. \n",
        "#you may consider adjusting certain things\n",
        "\n",
        "#like the number of subdivisions 64 runs faster but Colab GPU may not be big enough\n",
        "#if Colab GPU memory is too small, you will need to adjust subdivisions to 16\n",
        "%cat cfg/custom-yolov4-detector.cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTDne49ZEXiv"
      },
      "source": [
        "%cd /yolo_base/darknet\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T24tmt-DDiN8"
      },
      "source": [
        "#If you get CUDA out of memory adjust subdivisions above!\n",
        "#adjust max batches down for shorter training above\n",
        "!./darknet detector train data/obj.data cfg/custom-yolov4-detector.cfg yolov4.conv.137 -dont_show -map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oak23d2asVyx"
      },
      "source": [
        "Executing this cell will start training the neural network from the last known point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSdeJxTEnugg"
      },
      "source": [
        "!./darknet detector train data/obj.data cfg/custom-yolov4-detector.cfg backup/custom-yolov4-detector_last.weights -dont_show -map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-KYcFMVEIAE"
      },
      "source": [
        "# Infer custom objects with saved weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a-ugWakELm6"
      },
      "source": [
        "#check if weigths have saved yet\n",
        "#backup houses the last weights for our detector\n",
        "#(file yolo-obj_last.weights will be saved to the build\\darknet\\x64\\backup\\ for each 100 iterations)\n",
        "#(file yolo-obj_xxxx.weights will be saved to the build\\darknet\\x64\\backup\\ for each 1000 iterations)\n",
        "#After training is complete - get result yolo-obj_final.weights from path build\\darknet\\x64\\bac\n",
        "!ls backup\n",
        "#if it is empty you haven't trained for long enough yet, you need to train for at least 100 iterations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uGahFS-ESfl"
      },
      "source": [
        "import os\n",
        "\n",
        "#define utility function\n",
        "def imShow(path):\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  #plt.rcParams['figure.figsize'] = [10, 5]\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()\n",
        "\n",
        "#/test has images that we can test our detector on\n",
        "#test_images = [f for f in os.listdir('test') if f.endswith('.jpg')]\n",
        "import random\n",
        "#img_path = \"test/\" + random.choice(test_images);\n",
        "# can use {img_path} instead of path, if test folder i available\n",
        "#Yolo 4 config\n",
        "! ./darknet detector test \\\n",
        "cfg/coco.data \\\n",
        "../../../config_weights/yolo_minor/yolov3_custom_C4_C3_C4D_C3D.cfg \\\n",
        "../../../config_weights/yolo_minor/yolov3_custom_final.weights \\\n",
        " ../config_weights/yolo_minor/test.jpg\n",
        "#Yolo 3 minor group config\n",
        "#!./darknet detector test cfg/coco.data ../config_weights/yolo_minor/yolov3_custom_C4_C3_C4D_C3D.cfg ../config_weights/yolo_minor/yolov3_custom_final.weights ../config_weights/yolo_minor/test.jpg \n",
        "imShow('predictions.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG1ZTiLrfM8e"
      },
      "source": [
        "# Inferencing Yolo detector with OpenCV DNN module\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPhRA0oqeats"
      },
      "source": [
        "!cp -r \"/content/drive/My Drive/sewer_inspection/opencv_gpu/cv2.cpython-36m-x86_64-linux-gnu.so\" ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVIiR4r4ffFq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bbe7e49b-d965-4179-ac30-c312395e4bb1"
      },
      "source": [
        "# import the necessary packages\n",
        "import numpy as np\n",
        "import time\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow \n",
        "\n",
        "cv2.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4.5.0-dev'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHw4eq5HgqYE"
      },
      "source": [
        "#Yolo4\n",
        "labelsPath = '/content/drive/My Drive/sewer_inspection/yolo_detector/config_weights/yolo4/obj.names'  # damages label path\n",
        "weightsPath = '/content/drive/My Drive/sewer_inspection/yolo_detector/config_weights/yolo4/custom-yolov4-detector_best.weights'  # damages paths\n",
        "configPath = '/content/drive/My Drive/sewer_inspection/yolo_detector/config_weights/yolo4/yolov4-custom.cfg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YzVyWSAgtiD"
      },
      "source": [
        "#Yolo3 minor\n",
        "labelsPath='/content/drive/My Drive/sewer_inspection/yolo_detector/config_weights/yolo_minor/obj.names'\n",
        "weightsPath = '/content/drive/My Drive/sewer_inspection/yolo_detector/config_weights/yolo_minor/yolov3_custom_C3_C4_C3D_C4D_I.weights'  # damages paths\n",
        "configPath = '/content/drive/My Drive/sewer_inspection/yolo_detector/config_weights/yolo_minor/yolov3_custom_C4_C3_C4D_C3D_I.cfg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S1jN5t_fhmH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe763cb-9201-4377-9432-d4d1b340b819"
      },
      "source": [
        "print(\"[INFO] loading YOLO from disk...\")\n",
        "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
        "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
        "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
        "\n",
        "# initialize a list of colors to represent each possible class label\n",
        "np.random.seed(42)\n",
        "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype=\"uint8\")\n",
        "\n",
        "# determine only the *output* layer names that we need from YOLO\n",
        "ln = net.getLayerNames()\n",
        "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading YOLO from disk...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kokxtiv2pkf4"
      },
      "source": [
        "# NN params\n",
        "confidence_param = 0.30\n",
        "thresh_param = 0.25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huYdlQxJcKAe"
      },
      "source": [
        "### Test with image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzO9x1r6gd30"
      },
      "source": [
        "def detect_from_image(frame, verbose = False):\n",
        "  try:            \n",
        "      (H, W) = frame.shape[:2]\n",
        "      blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416),\tswapRB=False, crop=False)\n",
        "      net.setInput(blob)\n",
        "      start = time.time()\n",
        "      layerOutputs = net.forward(ln)\n",
        "      end = time.time()\n",
        "      elap = (end - start)\n",
        "      print(\"[INFO] single frame took {:.4f} seconds\".format(elap))\n",
        "      # initialize our lists of detected bounding boxes, confidences,\n",
        "      # and class IDs, respectively\n",
        "      boxes = []\n",
        "      confidences = []\n",
        "      classIDs = []\n",
        "  # loop over each of the layer outputs\n",
        "      for output in layerOutputs:\n",
        "          # loop over each of the detections\n",
        "          for detection in output:\n",
        "              # extract the class ID and confidence (i.e., probability)\n",
        "              # of the current object detection\n",
        "              scores = detection[5:]\n",
        "              classID = np.argmax(scores)\n",
        "              confidence = scores[classID]\n",
        "\n",
        "              # filter out weak predictions by ensuring the detected\n",
        "              # probability is greater than the minimum probability\n",
        "              if confidence > confidence_param:\n",
        "                  # scale the bounding box coordinates back relative to\n",
        "                  # the size of the image, keeping in mind that YOLO\n",
        "                  # actually returns the center (x, y)-coordinates of\n",
        "                  # the bounding box followed by the boxes' width and\n",
        "                  # height\n",
        "                  box = detection[0:4] * np.array([W, H, W, H])\n",
        "                  (centerX, centerY, width, height) = box.astype(\"int\")\n",
        "\n",
        "                  # use the center (x, y)-coordinates to derive the top\n",
        "                  # and and left corner of the bounding box\n",
        "                  x = int(centerX - (width / 2))\n",
        "                  y = int(centerY - (height / 2))\n",
        "\n",
        "                  # update our list of bounding box coordinates,\n",
        "                  # confidences, and class IDs\n",
        "                  boxes.append([x, y, int(width), int(height)])\n",
        "                  confidences.append(float(confidence))\n",
        "                  classIDs.append(classID)\n",
        "                  if verbose :\n",
        "                    print(\"Score:{} ClassId:{} Confidence:{} boxes:{}\".format(scores,classID, confidence, [x, y, int(width), int(height)]))\n",
        "\n",
        "\n",
        "  # apply non-maxima suppression to suppress weak, overlapping\n",
        "  # bounding boxes\n",
        "      idxs = cv2.dnn.NMSBoxes(boxes, confidences, confidence_param,\n",
        "                              thresh_param)\n",
        "\n",
        "      # ensure at least one detection exists\n",
        "      if len(idxs) > 0:\n",
        "          # loop over the indexes we are keeping\n",
        "          for i in idxs.flatten():\n",
        "              # extract the bounding box coordinates\n",
        "              (x, y) = (boxes[i][0], boxes[i][1])\n",
        "              (w, h) = (boxes[i][2], boxes[i][3])\n",
        "\n",
        "              # draw a bounding box rectangle and label on the frame\n",
        "              color = [int(c) for c in COLORS[classIDs[i]]]\n",
        "              cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
        "              text = \"{}: {:.4f}\".format(LABELS[classIDs[i]],\n",
        "                                        confidences[i])\n",
        "              cv2.putText(frame, text, (x, y - 5),\n",
        "                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)       \n",
        "            # some information on processing single frame\n",
        "  except Exception as e:\n",
        "    print(\"something happened: \", e)\n",
        "      \n",
        "  return frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv4QvKmOf98N"
      },
      "source": [
        "# read input image\n",
        "image_path='/content/drive/My Drive/sewer_inspection/yolo_detector/config_weights/yolo_minor/1.png'\n",
        "image = cv2.imread(image_path)\n",
        "# process image\n",
        "processed = detect_from_image(image, True)\n",
        "# display\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSZ7koJOCyIp"
      },
      "source": [
        "print(\"reading video\")\n",
        "cam = cv2.VideoCapture('/content/drive/My Drive/sewer_inspection/yolo_detector/config_weights/high_quality.mpg')\n",
        "ret, frame = cam.read()\n",
        "\n",
        "while cam.isOpened():\n",
        "    ret, frame = cam.read()\n",
        "    frame = detect_from_image(frame, False)\n",
        "    cv2_imshow(frame)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFmSnOP4e0hm"
      },
      "source": [
        "print(\"reading video\")\n",
        "cam = cv2.VideoCapture('/content/drive/My Drive/sewer_inspection/yolo_detector/config_weights/high_quality.mpg')\n",
        "ret, frame = cam.read()\n",
        "\n",
        "height, width, layers = frame.shape\n",
        "\n",
        "\n",
        "name = '/content/drive/My Drive/sewer_inspection/yolo_detector/infered.avi'\n",
        "out = cv2.VideoWriter(name, cv2.VideoWriter_fourcc(*'DIVX'), 25, (width, height))\n",
        "counter1000frames = 0\n",
        "while cam.isOpened():\n",
        "    ret, frame = cam.read()\n",
        "    frame = detect_from_image(frame, False)\n",
        "    out.write(frame)\n",
        "\n",
        "out.release()\n",
        "\n",
        "print(\"saved {}\" ,name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}