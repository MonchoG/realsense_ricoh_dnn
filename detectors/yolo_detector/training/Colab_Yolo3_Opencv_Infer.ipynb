{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Yolo3DamageDetector",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U14PdYadlYpM"
      },
      "source": [
        "## Download builded OpenCV with gpu support\n",
        "The building opencv from sources is required in order to use DNN module with GPU. That step was alreayd done and using the cell below, it will copy the required files to run Opencv DNN with GPU in the colab environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqiBexjri1Tb",
        "outputId": "074eca78-a938-46cd-90f1-dba7b08d56d0"
      },
      "source": [
        "# download opencv\n",
        "!gdown --id 1-0mj_acbT7LuV56ktYHjHVCp-kUaHsK8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-0mj_acbT7LuV56ktYHjHVCp-kUaHsK8\n",
            "To: /content/cv2.cpython-36m-x86_64-linux-gnu.so\n",
            "973MB [00:04, 219MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J35A0Bultzu"
      },
      "source": [
        "## Download yolo3 configuration, weights, labels\n",
        "This cell downloads to the colab environment the yolo3 detector from the minor group."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeOTyd8aZdwA",
        "outputId": "9a183026-dd78-4e96-e94c-ea5f2564a36c"
      },
      "source": [
        "# download yolo cfg\n",
        "!gdown --id 1W8FO1appY9HXIT-MsAUV-bbYpXRpX9zr\n",
        "# download yolo weights\n",
        "!gdown --id 15PMgapgWLettfzXANaTcDZBOPpNkJ7q6\n",
        "# download yolo labels\n",
        "!gdown --id 1HFwN9JLLgEMvg7YlZKiPE-bSOtZSb5r1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1W8FO1appY9HXIT-MsAUV-bbYpXRpX9zr\n",
            "To: /content/yolov3_custom_C4_C3_C4D_C3D_I.cfg\n",
            "100% 8.33k/8.33k [00:00<00:00, 15.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15PMgapgWLettfzXANaTcDZBOPpNkJ7q6\n",
            "To: /content/yolov3_custom_C3_C4_C3D_C4D_I.weights\n",
            "246MB [00:01, 162MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HFwN9JLLgEMvg7YlZKiPE-bSOtZSb5r1\n",
            "To: /content/obj.names\n",
            "100% 16.0/16.0 [00:00<00:00, 14.1kB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZnpJHHkl3Ao"
      },
      "source": [
        "# Check installation\n",
        "This cell shold execute without problems and if 4.5.0-dev is printed for opencv version everything is ok."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "x7hijB97gM3M",
        "outputId": "fcc9da0b-bd89-40ad-d9d4-7e633397b9a7"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import cv2\n",
        "#from google.colab.patches import cv2_imshow \n",
        "\n",
        "cv2.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4.5.0-dev'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rN164Jel-bn"
      },
      "source": [
        "# Setting paths to yolo detector\n",
        "Set the required paths to the labels map, the configuration file and weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVv75xTihqJn"
      },
      "source": [
        "#Yolo3 minor\n",
        "labelsPath='./obj.names'\n",
        "weightsPath = './yolov3_custom_C3_C4_C3D_C4D_I.weights'  # damages paths\n",
        "configPath = './yolov3_custom_C4_C3_C4D_C3D_I.cfg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDApHRy3hylm",
        "outputId": "21abe917-babd-4b3a-d603-30d12724de48"
      },
      "source": [
        "ls ./"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cv2.cpython-36m-x86_64-linux-gnu.so  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n",
            "\u001b[01;34mdrive\u001b[0m/                               yolov3_custom_C3_C4_C3D_C4D_I.weights\n",
            "obj.names                            yolov3_custom_C4_C3_C4D_C3D_I.cfg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQOdqBOymEmZ"
      },
      "source": [
        "## NN parameters\n",
        "These parameters can be changed and they control how much results are displayed and the confidence threshold for the detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctm7a1SDiLv6"
      },
      "source": [
        "# NN params\n",
        "confidence_param = 0.35\n",
        "thresh_param = 0.25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6eN8UXpmPGy"
      },
      "source": [
        "## Initialize the neural network\n",
        "loads the yolo configuration into the working environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBdF6TMlh4al",
        "outputId": "22c2e03c-e737-48f7-a824-c472f7092524"
      },
      "source": [
        "print(\"[INFO] loading YOLO from disk...\")\n",
        "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
        "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
        "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
        "\n",
        "# initialize a list of colors to represent each possible class label\n",
        "np.random.seed(42)\n",
        "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype=\"uint8\")\n",
        "\n",
        "# determine only the *output* layer names that we need from YOLO\n",
        "ln = net.getLayerNames()\n",
        "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading YOLO from disk...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HiGhzfTmXOD"
      },
      "source": [
        "# Define function for performing detection\n",
        "This method takes as input image and optional flag - if true, information about each detection will be logged (confidence, labelId, bounding box coordinates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAT1MJhFiN8-"
      },
      "source": [
        "def detect_from_image(frame, verbose = False):\n",
        "  try:            \n",
        "      (H, W) = frame.shape[:2]\n",
        "      blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416),\tswapRB=False, crop=False)\n",
        "      net.setInput(blob)\n",
        "      #start = time.time()\n",
        "      layerOutputs = net.forward(ln)\n",
        "      #end = time.time()\n",
        "      #elap = (end - start)\n",
        "      #print(\"[INFO] single frame took {:.4f} seconds\".format(elap))\n",
        "      # initialize our lists of detected bounding boxes, confidences,\n",
        "      # and class IDs, respectively\n",
        "      boxes = []\n",
        "      confidences = []\n",
        "      classIDs = []\n",
        "  # loop over each of the layer outputs\n",
        "      for output in layerOutputs:\n",
        "          # loop over each of the detections\n",
        "          for detection in output:\n",
        "              # extract the class ID and confidence (i.e., probability)\n",
        "              # of the current object detection\n",
        "              scores = detection[5:]\n",
        "              classID = np.argmax(scores)\n",
        "              confidence = scores[classID]\n",
        "\n",
        "              # filter out weak predictions by ensuring the detected\n",
        "              # probability is greater than the minimum probability\n",
        "              if confidence > confidence_param:\n",
        "                  # scale the bounding box coordinates back relative to\n",
        "                  # the size of the image, keeping in mind that YOLO\n",
        "                  # actually returns the center (x, y)-coordinates of\n",
        "                  # the bounding box followed by the boxes' width and\n",
        "                  # height\n",
        "                  box = detection[0:4] * np.array([W, H, W, H])\n",
        "                  (centerX, centerY, width, height) = box.astype(\"int\")\n",
        "\n",
        "                  # use the center (x, y)-coordinates to derive the top\n",
        "                  # and and left corner of the bounding box\n",
        "                  x = int(centerX - (width / 2))\n",
        "                  y = int(centerY - (height / 2))\n",
        "\n",
        "                  # update our list of bounding box coordinates,\n",
        "                  # confidences, and class IDs\n",
        "                  boxes.append([x, y, int(width), int(height)])\n",
        "                  confidences.append(float(confidence))\n",
        "                  classIDs.append(classID)\n",
        "                  if verbose :\n",
        "                    print(\"Score:{} ClassId:{} Confidence:{} boxes:{}\".format(scores,classID, confidence, [x, y, int(width), int(height)]))\n",
        "\n",
        "\n",
        "  # apply non-maxima suppression to suppress weak, overlapping\n",
        "  # bounding boxes\n",
        "      idxs = cv2.dnn.NMSBoxes(boxes, confidences, confidence_param,\n",
        "                              thresh_param)\n",
        "\n",
        "      # ensure at least one detection exists\n",
        "      if len(idxs) > 0:\n",
        "          # loop over the indexes we are keeping\n",
        "          for i in idxs.flatten():\n",
        "              # extract the bounding box coordinates\n",
        "              (x, y) = (boxes[i][0], boxes[i][1])\n",
        "              (w, h) = (boxes[i][2], boxes[i][3])\n",
        "\n",
        "              # draw a bounding box rectangle and label on the frame\n",
        "              color = [int(c) for c in COLORS[classIDs[i]]]\n",
        "              cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
        "              text = \"{}: {:.4f}\".format(LABELS[classIDs[i]],\n",
        "                                        confidences[i])\n",
        "              cv2.putText(frame, text, (x, y - 5),\n",
        "                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)       \n",
        "            # some information on processing single frame\n",
        "  except Exception as e:\n",
        "    print(\"something happened: \", e)\n",
        "      \n",
        "  return frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRt-L3ccmnKY"
      },
      "source": [
        "## Download test image and video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgn8DBORiXJy",
        "outputId": "29c0c398-917f-48bb-c32b-7c8e9ff74996"
      },
      "source": [
        "# download image\n",
        "!gdown --id 1AQiGNNsVJo4NVZlj0L0s-qmHRKEpOwSv\n",
        "# download video\n",
        "!gdown --id 1UUp4aGyu8gips1hjIGc1DANGdP8pCu8k"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AQiGNNsVJo4NVZlj0L0s-qmHRKEpOwSv\n",
            "To: /content/1.png\n",
            "100% 373k/373k [00:00<00:00, 59.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UUp4aGyu8gips1hjIGc1DANGdP8pCu8k\n",
            "To: /content/inspc.mpg\n",
            "695MB [00:13, 51.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8O32j8XumptJ"
      },
      "source": [
        "# Testing\n",
        "The first cell tests the detector with the downloaded image\n",
        "The second cell tests the detector with the downloaded video and saves it after it is done reading."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcd43SQNUCcU"
      },
      "source": [
        "image_path='./corrosion.JPG'\n",
        "image_path='./crackHd2.png'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1WMnhp7-iPUE"
      },
      "source": [
        "# read input image\n",
        "image_path='./corrosion.JPG'  # you can change the path to any image, if you upload different file\n",
        "image = cv2.imread(image_path)\n",
        "# process image\n",
        "processed = detect_from_image(image, True)\n",
        "# display\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1h4sazHm8nm"
      },
      "source": [
        "### Note\n",
        "This script has few variable that can be changed\n",
        "* width & height - desired output for the resulting video\n",
        "* count - the number of frames to read from the video ( this might be needed in the colab environment because of memory issues, lower the number if there are any)\n",
        "* logging apears to take up a lot of ram as well, consider commenting out the inference speed timer & print; also set detect_from_image(..., verbose=False) verbose prints bounding boxes, label and confidence for detections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srMdGqsfiQbq"
      },
      "source": [
        "print(\"reading video\")\n",
        "cam = cv2.VideoCapture('inspc.mpg')\n",
        "#ret, frame = cam.read()\n",
        "vid_arr = []\n",
        "frame_counter = 0\n",
        "# scale_percent = 40 # percent of original size\n",
        "# width = int(frame.shape[1] * scale_percent / 100)\n",
        "# height = int(frame.shape[0] * scale_percent / 100)\n",
        "#width = 1920\n",
        "#height = 1080\n",
        "# dim = (width, height)\n",
        "# resize image\n",
        "\n",
        "counter1000frames = 1\n",
        "#count = 1000\n",
        "while cam.isOpened():\n",
        "    ret, frame = cam.read()\n",
        "    #frame = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
        "    height, width, layers = frame.shape\n",
        "\n",
        "    frame_counter+=1\n",
        "    if frame_counter == 5:\n",
        "      frame = detect_from_image(frame, True)\n",
        "      vid_arr.append(frame)\n",
        "      frame_counter = 0\n",
        "    if len(vid_arr) >= 5000:\n",
        "    #   counter1000frames +=5\n",
        "       break\n",
        "name = 'infered' + str(counter1000frames) +'.avi'\n",
        "out = cv2.VideoWriter(name, cv2.VideoWriter_fourcc(*'DIVX'), 15, (width, height))\n",
        "for i in range(len(vid_arr)):\n",
        "    out.write(vid_arr[i])\n",
        "out.release()\n",
        "frame_counter = 0\n",
        "# vid_arr = None\n",
        "# vid_arr = []\n",
        "print(\"saved {}\" ,name)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}